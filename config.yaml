llm_provider: "google"
model: "gemini-1.5-pro-latest"
generation_config:
  temperature: 0.7
  top_p: 1.0
  max_output_tokens: 1024
